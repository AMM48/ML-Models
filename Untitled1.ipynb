{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwCBH9EgYQC72T+hiec7Fm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AMM48/ML-Models/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U imbalanced-learn"
      ],
      "metadata": {
        "id": "zWfu58pYXOEp",
        "outputId": "7c2ef2fe-1596-47e3-aa1e-081361e67678",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Collecting imbalanced-learn\n",
            "  Downloading imbalanced_learn-0.11.0-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.6/235.6 kB\u001b[0m \u001b[31m766.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.2.0)\n",
            "Installing collected packages: imbalanced-learn\n",
            "  Attempting uninstall: imbalanced-learn\n",
            "    Found existing installation: imbalanced-learn 0.10.1\n",
            "    Uninstalling imbalanced-learn-0.10.1:\n",
            "      Successfully uninstalled imbalanced-learn-0.10.1\n",
            "Successfully installed imbalanced-learn-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import *\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.preprocessing import add_dummy_feature\n",
        "import joblib\n",
        "from imblearn.over_sampling import SMOTE\n",
        "df = pd.read_excel('dataSet (1).xlsx')\n",
        "df = df.dropna()\n",
        "categories = {\n",
        "    'Food': ['restaurant', 'eatery', 'diner', 'bistro', 'brasserie', 'tavern', 'pizzeria', 'steakhouse', 'steak',\n",
        "             'bar', 'sushi bar', 'burger', 'bbq', 'noodle', 'breakfast', 'break fast', 'lunch', 'diner',\n",
        "             'dining', 'buffet', 'seafood', 'ramen', 'sweet', 'bakery', 'ice cream',\n",
        "             'icecream', 'grill','hunger','hungry','sandwich','donut','donuts','sandwiches',\n",
        "             'doughnuts','hungerstation','hungerstat','mcdonald','mcdonalds','kfc',\n",
        "             'dunkin','krispy kreme','baik','albaik','tazaj','fakeih',\n",
        "             'shawarma','shawerma','dominos','burgerizzr', 'hardees', 'chefs', 'chefz', 'the chefz'],\n",
        "    'Coffee': ['cafee', 'coffee', 'espresso', 'bistro', 'teahouse', 'café', 'riastery', 'coffeehouse',\n",
        "               'caf', 'bean', 'beans', 'caffe', 'cafe', 'roast', 'roastrie', \"barn's\",\n",
        "               'barns', 'barnscafe', 'barncafe', 'starbucks', 'bon', 'dose',\n",
        "               'overdose', \"joffrey's\"\n",
        "              ],\n",
        "    'Grocery': ['supermarket', \t'super market'\t,'market'\t,'grocery store'\t,'hypermarket'\t,'hyper'\t,'superstore'\t,\n",
        "               \t'fruits'\t,'fruit'\t,'foodstuf'\t,'foodstuff'\t,'danube'\t,'lulu'\t,'panda'\t,\n",
        "               \t'carrefour'\t,'manuel'\t,'markets'\t,'othaim'\t,'tamimi'\t,\n",
        "               \t'retail','bindawood'\t,'meed'],\n",
        "    'Health': ['hospital', \t'clinic', \t'medical', \t'health', \t'care', \t'pharmacy', \t'doctor', \t'dentist',\n",
        "               'emergency', \t'er', \t'therapy', \t'care center', \t'spa', \t'beauty', \t'salon',\n",
        "               'hair', \t'nail', \t'barber', \t'massage',\n",
        "               'wax', \t'waxing',\n",
        "               'body',\n",
        "               'make up',\n",
        "               'makeup',\n",
        "               'laser hair',\n",
        "               'fitness',\n",
        "               'fit',\n",
        "               'yoga',\n",
        "               'weight',\n",
        "               'health',\n",
        "               'workout',\n",
        "               'training',\n",
        "               'gym',\n",
        "               'crossfit',\n",
        "               'cardio',\n",
        "               \"nahdi\",\n",
        "               \"alnahdi\",\n",
        "               \"whites\",\n",
        "               \"al nahdi\",\n",
        "               \"barbershop\", \"mafasel\", \"mafasel c\"],\n",
        "    'Transportation': ['gas', \t'petrol', \t'station', \t'gasstation',\n",
        "                       'fuel', \t'refueling',\n",
        "                       'filling station',\n",
        "                       'diesel',\n",
        "                       'pump',\n",
        "                       'naft',\n",
        "                       'motor',\n",
        "                       'vehicle',\n",
        "                       \"parkin\",\n",
        "                       \"parking\",\n",
        "                       \"air\",\n",
        "                       \"airline\",\n",
        "                       \"airlines\",\n",
        "                       \"aldrees\",\n",
        "                       \"petromin\",\n",
        "                       \"sahel\",\n",
        "                       \"al-adel\",\n",
        "                       \"petrosven\",\n",
        "                       \"quraish\",\n",
        "                       \"al musaidya\",\n",
        "                       \"al-andalus\",\n",
        "                       \"andalus\",\n",
        "                       \"sasco\"],\n",
        "    'Shopping': ['retail', \t'mall' , \t'shop' , \t'shopping' , \t'boutique' , \t'outlet' , \t'plaza' , \t'center',\n",
        "                 'retailer', \t'fashion', \t'clothing', \t'shoe', \t'gift', \t'art',\n",
        "                 'jewelry', \t'clothes', \t'storefront',\n",
        "                 'book', \t'books',\n",
        "                 'store',\n",
        "                 'bookstore',\n",
        "                 'sport',\n",
        "                 'sports',\n",
        "                 \"cente\",\n",
        "                 \"zara\",\n",
        "                 \"jarir\",\n",
        "                 \"prada\",\n",
        "                 \"gucci\",\n",
        "                 \"next\",\n",
        "                 \"redtag\",\n",
        "                 \"boulevard\",\n",
        "                 \"thobe\",\n",
        "                 \"lomar\",\n",
        "                 \"sindi\",\n",
        "                 \"h&m\",\n",
        "                 \"burberry\",\n",
        "                 \"jewellery\",\n",
        "                 \"tiffany\",\n",
        "                 \"jewelry\",\n",
        "                 \"cartier\",\n",
        "                 \"rolex\",\n",
        "                 \"ikea\",\n",
        "                 \"extra\",\n",
        "                 \"saco\"]\n",
        "}\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df['Messages'])\n",
        "\n",
        "for category, words in categories.items():\n",
        "    for word in words:\n",
        "        word_feature = df['Messages'].apply(lambda x: x.lower().count(word))\n",
        "        X = add_dummy_feature(X, word_feature)\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, df['Category'])\n",
        "\n",
        "clf = SVC(probability=True)\n",
        "\n",
        "scores = cross_val_score(clf, X_resampled, y_resampled, cv=5)\n",
        "\n",
        "print(\"Cross-validation scores: \", scores * 100)\n",
        "print(\"Average cross-validation score: \", scores.mean() * 100)\n",
        "\n",
        "clf.fit(X_resampled, y_resampled)\n",
        "\n",
        "joblib.dump(clf, 'model.joblib')\n",
        "\n",
        "joblib.dump(vectorizer, 'vectorizer.joblib')\n",
        "\n",
        "loaded_model = joblib.load('model.joblib')\n",
        "\n",
        "test_df = ['''POS Purchase\n",
        "Amount 34 SAR\n",
        "At al nahdi\n",
        "Mada-Apple pay *0007\n",
        "on 13/09/23 at 00:25''']\n",
        "\n",
        "test_X = vectorizer.transform(test_df)\n",
        "\n",
        "for category, words in categories.items():\n",
        "    for word in words:\n",
        "        word_feature = [test_df[0].lower().count(word)]\n",
        "        test_X = add_dummy_feature(test_X, word_feature)\n",
        "\n",
        "predictions = loaded_model.predict(test_X)\n",
        "probabilities = loaded_model.predict_proba(test_X)\n",
        "\n",
        "\n",
        "print(\"Accuracy:\", predictions[0])\n",
        "print(\"Classification Report:\\n\", probabilities * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlrHBQzxC1QA",
        "outputId": "eb143ca3-3739-475c-bc87-f9728008c950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores:  [83.33333333 70.83333333 70.83333333 91.66666667 91.66666667]\n",
            "Average cross-validation score:  81.66666666666667\n",
            "Accuracy: Health\n",
            "Classification Report:\n",
            " [[10.62700936 24.26486294 12.8126583  34.92980477 12.5748159   4.79084874]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_instance = ['''شراء-POS\n",
        "بـ500 SAR\n",
        "من mafasel\n",
        "مدى-أثير*2566\n",
        "في 05/11/23 13:33''']\n",
        "\n",
        "new_instance_counts = vectorizer.transform(new_instance)\n",
        "\n",
        "for category, words in categories.items():\n",
        "    for word in words:\n",
        "        word_feature = [new_instance[0].lower().count(word)]\n",
        "        new_instance_counts = add_dummy_feature(new_instance_counts, word_feature)\n",
        "\n",
        "new_prediction = clf.predict(new_instance_counts)\n",
        "confidence_levels = clf.predict_proba(new_instance_counts)\n",
        "predicted_category = new_prediction[0]\n",
        "print(\"The predicted category is:\", predicted_category)\n",
        "\n",
        "predicted_category_index = list(clf.classes_).index(predicted_category)\n",
        "\n",
        "confidence_for_predicted_category = confidence_levels[0][predicted_category_index]\n",
        "print(f\"Confidence for {predicted_category}: {confidence_for_predicted_category * 100}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EV4oH-EeaOGy",
        "outputId": "43d7452f-afaa-499d-afcf-804be8eaa969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted category is: Shopping\n",
            "Confidence for Shopping: 22.064427864948406\n"
          ]
        }
      ]
    }
  ]
}